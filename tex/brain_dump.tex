% Created 2012-09-21 Fri 13:21
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\tolerance=1000
\usepackage{listings}
\lstset { language=Haskell}
\providecommand{\alert}[1]{\textbf{#1}}

\title{Pony Working Document}
\author{Andrew Hirsch}
\date{\today}

\begin{document}

\maketitle


\section{Introduction}
\label{sec-1}


In Pony, we allow users to define extensions to a base language as transformations of that language. However, a user may be using more than one transformation at any particular time. If the user is attempting to apply transformations that conflict with each other, data may be overwritten by transformations in such a way that the transformations are no longer semantics-preserving; indeed, we may no longer create valid C99 code.

Most compilers will tell us when we are doing something wrong. Either they will give an error if given code that they cannot process, or they will give a warning if they recognize a pattern that is commonly a bug. We would like for Pony to detect such collisions for us, and give us a similar error.

To achieve this, we exploit the use of Data.Generics (``Scrap your boilerplate''-style coding) and the structure of programming languages as semantic trees.
\section{Strong Collision}
\label{sec-2}


In strong collision, we detect possible collisions between two transformations. We do this by looking at the code of the transformations; it should only run on certain types of nodes. The central idea is that we create a type theory the abstract syntax tree of the (possibly extended) language the transformation runs on.

The existence of BNF suggests that this is possible: if we have a BNF formula as follows:

\begin{verbatim}
<expression> ::= <expression> + <term>
              | <expression> - <term>
              | <term>                
\end{verbatim}

Then there must be a datatype in the tree correspondingly:

\begin{lstlisting}

data expression = Plus expression term
                | Minus expression term 
                | Standalone term

\end{lstlisting}

It should be possible (through dynamic programming) to create a listing of all node types that can be reached from an \verb~expression~ node. Any transformation that works on an \verb~expression~ node also affects all nodes reachable from the \verb~expression~ node. Thus, we can have a type theory of nodes with a subtyping relation.

What allows for tighter expressiveness for strong collision is the idea of guards. The idea here is that if you have the following transformation:

\begin{lstlisting}
trans :: Expr -> Expr
trans Plus e1 e2 = Minus e1 e2
trans Minus e1 e2 = Plus e1 e2
trans e@(Standalone _) = id e
\end{lstlisting}

We then \emph{refine} the type of trans to 

\begin{lstlisting}
trans :: Expr -> Expr | forall e. e = (Plus e1 e2) \/ (Minus e1 e2)
\end{lstlisting} 

For more complex transformations, this is the same as type inference for dependent types. A cursory search of the literature tells us that this may not be possible in the general case. (See: \href{http://research.microsoft.com/en-us/people/dimitris/pie.pdf}{Dependent Types: Easy as PIE} and \href{http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&cad=rja&ved=0CDsQFjAC&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.30.8049%26rep%3Drep1%26type%3Dpdf&ei=kOdXUIKzD8jp0QHzmoCwBg&usg=AFQjCNHhbxCQcN_3CiBI3SMJyzZpzvDrkw}{Type Inference and Reconstruction for First Order Dependent Types}.)

It appears from the above example that we don't have much added from guards. However, consider the following example:

\begin{lstlisting}
data NumType = NumFloat Float
             | NumInt Int   
             | NumLong Long 

doIntLong :: NumType -> NumType | forall (NumInt n). n > 0
doIntLong f@(NumFloat _) = id f
doIntLong i@(NumInt n)
   | n > 0 = NumLong n 
   | otherwise = id i
doIntLong l@(NumLong _) = id l

doIntFloat :: NumType -> NumType | forall (NumInt n). n <= 0
doIntFloat f@(NumFloat _) = id f
doIntFloat i@(NumInt n)
   | n <= 0 = NumFloat (fromInteger f) 
   | otherwise = id i                  
doIntFloat l@(NumLong _) = id l
\end{lstlisting}

As you can see, these transformations (\verb~doIntLong~ and \verb~doIntFloat~) will never collide. However, naively looking at the types they work on, even branching into the type to see what constructors it uses, would be too weak to decide this. But we see that is impossible to ever unify the refined types of \verb~doIntFloat~ and \verb~doIntLong~. Thus, our system, with guards, can tell that these transformations will compose.

However, even if this is not decidable in the general case, it may be possible to find correct types, but not types that are as ``tight'' as possible, and thus we would be too conservative in our warnings. However, this would be acceptable in most cases.
\section{Weak Collision}
\label{sec-3}


In weak collision, we detect only possible collisions between two transformations \emph{on a particular piece of code}. This requires a bit more work, but allows for pony transformations to be used in more general cases.

To do weak collision, we use the Curry-Howard correspondence to get a logical version of the transformations' Haskell code. We can then unify these over the database of tree nodes, using standard techniques of logic programming. 

This requires a library for getting logical forms of Haskell code. Currently, I am only aware of one library, and it only finds the propositional forms of types. Finding such a library, or a work-around, is paramount.
\section{Better Weak Collision?}
\label{sec-4}


Because our version of weak collision only works on the node level, it is possible that two transformations might be rejected because they work on the same node, but do not actually overwrite each other. However, detecting this kind of ``better weak collision'' is difficult, and is probably left for another day.
\section{Better Strong Collision?}
\label{sec-5}


The holy grail of this work would be to find an algorithm that would detect that two transformations are incompatible in \textbf{exactly} the cases where they may overwrite one another. However, this is an uncomputable problem (see: \href{http://en.wikipedia.org/wiki/Rice's_theorem}{Rice's Theorem}). It may very well be possible to create better versions of strong collision. However, this is difficult work, along the same lines of the work on halting (see: \href{http://research.microsoft.com/en-us/um/cambridge/projects/terminator/}{Microsoft Terminator}).

\end{document}
